{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1 ML2 BackPropogation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepshikharbhardwaj/ML-2-BackPropogation/blob/main/A1_ML2_BackPropogation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVuLYaVvyPVz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI5ZyuD4yfN5"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X, Y_in = iris.data, iris.target\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzlkpTbmCqqG"
      },
      "source": [
        "def oneHotVector(n):\n",
        "  b=[]\n",
        "  #a=int(input())\n",
        "  a=3 # number of class\n",
        "  for i in range(a):\n",
        "    if(i==n):\n",
        "      b.append(1.0)\n",
        "    else:\n",
        "      b.append(0.0)\n",
        "  return b"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b27s_n39V9gL"
      },
      "source": [
        "Y=[]\n",
        "for i in range(len(Y_in)):\n",
        "  #print(Y_in[i])\n",
        "  y=oneHotVector(Y_in[i])\n",
        "  Y.append(y)\n",
        "Y=np.array(Y)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zaf0NzWy-qn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrW71iOVzCCK"
      },
      "source": [
        "def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=10, nodes=[], lr=0.15):\n",
        "    hidden_layers = len(nodes) - 1\n",
        "    weights = InitializeWeights(nodes)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        weights = Train(X_train, Y_train, lr, weights)\n",
        "\n",
        "        if(epoch % 20 == 0):\n",
        "            print(\"Epoch {}\".format(epoch))\n",
        "            print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
        "            print(\"Test Accuracy:{}\".format(Accuracy(X_test, Y_test, weights)))\n",
        "           \n",
        "    return weights\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymETaU-kzIU2"
      },
      "source": [
        "def InitializeWeights(nodes):\n",
        "    \"\"\"Initialize weights with random values in [-1, 1] (including bias)\"\"\"\n",
        "    layers, weights = len(nodes), []\n",
        "    \n",
        "    for i in range(1, layers):\n",
        "        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n",
        "              for j in range(nodes[i])]\n",
        "        weights.append(np.matrix(w))\n",
        "    \n",
        "    return weights"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOIo6_1zzLBE"
      },
      "source": [
        "def ForwardPropagation(x, weights, layers):\n",
        "    activations, layer_input = [x], x\n",
        "    for j in range(layers):\n",
        "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
        "        #print(\"activation\",activation)\n",
        "        #input()\n",
        "        activations.append(activation)\n",
        "        layer_input = np.append(1, activation) # Augment with bias\n",
        "    #print(\"activations----------------\",activations)\n",
        "    #input()\n",
        "    return activations"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ9RilOGzOD8"
      },
      "source": [
        "def BackPropagation(y, activations, weights, layers):\n",
        "    outputFinal = activations[-1]\n",
        "    error = np.matrix(y - outputFinal) # Error at output\n",
        "    \n",
        "    for j in range(layers, 0, -1):\n",
        "        currActivation = activations[j]\n",
        "       #print(\"currActivation\",currActivation)\n",
        "        #input()\n",
        "        \n",
        "        if(j > 1):\n",
        "            # Augment previous activation\n",
        "            prevActivation = np.append(1, activations[j-1])\n",
        "        else:\n",
        "            # First hidden layer, prevActivation is input (without bias)\n",
        "            prevActivation = activations[0]\n",
        "        \n",
        "        delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
        "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
        "\n",
        "        w = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n",
        "        error = np.dot(delta, w) # Calculate error for current layer\n",
        "    \n",
        "    return weights"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rR9fm35zQvr"
      },
      "source": [
        "def Train(X, Y, lr, weights):\n",
        "    layers = len(weights)\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], Y[i]\n",
        "        x = np.matrix(np.append(1, x)) # Augment feature vector\n",
        "        \n",
        "        activations = ForwardPropagation(x, weights, layers)\n",
        "        weights = BackPropagation(y, activations, weights, layers)\n",
        "\n",
        "    return weights"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cGaHQkdzTzk"
      },
      "source": [
        "def Sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def SigmoidDerivative(x):\n",
        "    return np.multiply(x, 1-x)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx2UpMGozXNu"
      },
      "source": [
        "def Predict(item, weights):\n",
        "    layers = len(weights)\n",
        "    item = np.append(1, item) # Augment feature vector\n",
        "    \n",
        "    ##_Forward Propagation_##\n",
        "    activations = ForwardPropagation(item, weights, layers)\n",
        "    \n",
        "    outputFinal = activations[-1].A1\n",
        "    index = FindMaxActivation(outputFinal)\n",
        "\n",
        "    # Initialize prediction vector to zeros\n",
        "    y = [0 for i in range(len(outputFinal))]\n",
        "    y[index] = 1  # Set guessed class to 1\n",
        "\n",
        "    return y # Return prediction vector\n",
        "\n",
        "\n",
        "def FindMaxActivation(output):\n",
        "    \"\"\"Find max activation in output\"\"\"\n",
        "    m, index = output[0], 0\n",
        "    for i in range(1, len(output)):\n",
        "        if(output[i] > m):\n",
        "            m, index = output[i], i\n",
        "    \n",
        "    return index"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phHHW-7nzaTJ"
      },
      "source": [
        "def Accuracy(X, Y, weights):\n",
        "    \"\"\"Run set through network, find overall accuracy\"\"\"\n",
        "    correct = 0\n",
        "    #print(\"rr3\")\n",
        "    for i in range(len(X)):\n",
        "        #print(\"rr4\")\n",
        "        x, y = X[i], list(Y[i])\n",
        "      #  print(y)\n",
        "        #input()\n",
        "       # print(\"rr1\")\n",
        "        guess = Predict(x, weights)\n",
        "        #print(\"rr2\")\n",
        "\n",
        "        if(y == guess):\n",
        "            # Guessed correctly\n",
        "            correct += 1\n",
        "\n",
        "    return correct / len(X)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgk1bTlDgGWg"
      },
      "source": [
        "def main():\n",
        "  inputLayer=4\n",
        "  outputLayer=3\n",
        "  First_hiddenLayer=3\n",
        "  layers=[inputLayer,First_hiddenLayer,outputLayer]\n",
        "  total_hidden_layers = len(layers) - 1\n",
        "  weights=[]\n",
        "  w1=np.random.random((3,5))\n",
        "  weights.append(w1)\n",
        "  w2=np.random.random((3,4))\n",
        "  weights.append(w2)\n",
        "  ww=InitializeWeights(layers)\n",
        "  for i in weights:\n",
        "    print(\"weights\",weights)\n",
        "  for i in ww:\n",
        "    print(\"ww\",ww)\n",
        "  for epoch in range(1, epochs+1):\n",
        "    weights = Train(X_train, Y_train, lr, weights)\n",
        "    if(epoch % 20 == 0):\n",
        "      print(\"Epoch {}\".format(epoch))\n",
        "      print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
        "      print(\"Test Accuracy:{}\".format(Accuracy(X_test, Y_test, weights)))\n",
        "  \n",
        " \n",
        " "
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHRCw36_zduj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281c80f3-dd36-41dc-d0a3-4605e5a00211"
      },
      "source": [
        "f = len(X[0]) # Number of features\n",
        "o = len(Y[0]) # Number of outputs / classes\n",
        "\n",
        "layers = [f, 5, o] # Number of nodes in layers\n",
        "lr, epochs = 0.15, 100\n",
        "\n",
        "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs=epochs, nodes=layers, lr=lr);\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 20\n",
            "Training Accuracy:0.9722222222222222\n",
            "Test Accuracy:0.9333333333333333\n",
            "Epoch 40\n",
            "Training Accuracy:0.9814814814814815\n",
            "Test Accuracy:0.9333333333333333\n",
            "Epoch 60\n",
            "Training Accuracy:0.8981481481481481\n",
            "Test Accuracy:0.9\n",
            "Epoch 80\n",
            "Training Accuracy:0.8981481481481481\n",
            "Test Accuracy:0.9\n",
            "Epoch 100\n",
            "Training Accuracy:0.9814814814814815\n",
            "Test Accuracy:0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}